---
title: "Week 7 Data Exploration Project"
author: "Chequala Fuller"
date: "2/20/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

Before reading in the necessary data, we will need to load all libraries required to execute this analysis. 

```{r, echo = FALSE}
source("../code/01_dep_load_libraries.R")
```

## Read files

Once libraries are successfully loaded, read in the appropriate data files. For this data exploration project, we will be using the provided _Most+Recent+Cohorts+(Scorecard+Elements).csv_, _id_name_link.csv_, and twelve data files with the naming convention pattern _trend_up_to_xx.csv_ to perform our analysis.  To read these data files, we use the _list.files()_ and _map()_ functions from the _tidyverse_ package as well as the _read_csv_ from the built-in _readr_ package. The following data frames, values, and functions have been assigned and/or created to prepare for tidy data.


Dataframes         | No. Observations | No. Variables
------------------ | ---------------- | -------------
recent_cohorts     | 7804             | 122
id_name_link       | 3555             | 3
compile_data       | 1593740          | 6

Values             | Type
------------------ | ----------------
file_list          | chr [1:12]

Functions          | Parameter(s)
------------------ | ----------------
process_file       | function(filename)


```{r, echo = FALSE, results = 'hide'}
source("../code/02_dep_read_data.R")
```


## Tidy Data

Though all desired data has been read, it required more clean up to prepare for the regression model(s), graph(s) and analysis. First, I created a new data frame for the id name scorecards and called it scorecd_id_name. I chose to accomplish this by merging the recent_cohorts and id_name_link data frames together by both unit ID (UNITID) and ope ID (OPEID). Next, I created another data frame for the college scorecard through merging the scorecd_id_name data frame with our compile_data data frame by school name (SCHNAME). Considering the objective of the research question, this would give us a more comprehensive spreadsheet to work with.


After establishing the college scorecard (coll_scorecd), some more tidying was still needed and was accomplished by mutating and selecting specific variables for colleges which perdominantly grant bachelor's degrees (coll_scorecd_bs) to make it easier for modeling. This step also included isolation of the first ten characters of the MONTHORWEEK variable to make it easier to work with the date (DATE) associated with each observation. With the data in decent shape at this point, I was able to identify the threshold for median earnings by calculating the median of all median earnings for all colleges (MEDEARN10). Further defining the threshold for high-earnings (> 41,800 dollars) vs. low-earnings (<41,800 dollars).

To better make a direct comparison for this analysis, I converted the independent variable (INDEX) to a measure of standard deviations from its mean, creating a new data frame which groups the data by their key number (KEYNUM) and summarizes them. Finally, I added high earnings (HIGHEARN) binary variable to standardized_var data frame to use as the dummy variable (for all median earnings above threshold HIGHEARN = 1, else HIGHEARN = 0) and created data frames for data collected before the September 2015 release (pre_sept2015) as well as after (post_sept2015). This was decided because 


```{r, echo = FALSE, results = 'hide'}
source("../code/03_dep_tidy_data.R")
```


## Data Analysis


```{r, echo = FALSE}
#####################################################################
# BASE MODEL: Bivariate OLS regresssing median earnings             #
# (MEDEARN10) on standardized index (SD_INDEX)                      #                  
#####################################################################

model_base <- lm(MEDEARN10 ~ SD_INDEX, data = standardized_var)

ggplot(data = model_base, aes(x = SD_INDEX, y = MEDEARN10)) + 
geom_smooth() + 
labs(x = "Standardized Index", y = "Median Earnings",
     title = "Student Interest vs. Median  Earnings of Grads (Base Model)")
```


```{r, echo = FALSE}
####################################################################
# MODEL 1 & 2: Bivariate OLS regressing median earnings (MEDEARN10)#
# on standardized index (INDEX) prior to September 1, 2015         #
####################################################################

model_01 <- lm(MEDEARN10 ~ SD_INDEX, data = pre_sep2015)
model_02 <- lm(MEDEARN10 ~ SD_INDEX, data = post_sep2015) 
export_summs(model_01, model_02)


ggplot(data = model_01, aes(x = SD_INDEX, y = MEDEARN10)) +
  geom_smooth() + 
  labs(x = "Standardized Index", y = "Median Earnings",
       title = "Student Interest vs. Median  Earnings of Grads (Model 1: Before Sept 2015)")

ggplot(data = model_02, aes(x = SD_INDEX, y = MEDEARN10)) +
  geom_smooth() + 
  labs(x = "Standardized Index", y = "Median Earnings",
       title = "Student Interest vs. Median  Earnings of Grads (Model 2: After Sept 2015)")
```


```{r, echo = FALSE}

```

## The Writeup

How should the regression model be designed to answer the question           (transformations and functional form? Standard error adjustments?          etc.), and how can we interpret the results once we have them?

After performing the base models regressing median earnings on standardized index,the graphs had indicated that the graphs were nonlinear. Although nonlinear, between pre_sept15 regression (model_01) and post_sept15 (model_02), model_01 looked better than model_02. Therefore, I had decided to use model_01 and expand on it by adding multiple controls and a polynomial term to figure out if high earnings (HIGHEARN) follows a polynomial. Hopefully, immproving the regression model.

